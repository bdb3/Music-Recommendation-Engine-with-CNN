{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pandas import HDFStore, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootURL = \"C:/Users/Danny/Documents/spring18/DataScience/FinalProject/millionsongsubset_full/MillionSongSubset/data/\"\n",
    "import string\n",
    "s = string.ascii_uppercase[:27]\n",
    "azlist = []\n",
    "filenames = []\n",
    "for b in range(26):\n",
    "    azlist.append(s[b])\n",
    "for a in range(2):\n",
    "    if (a == 0):\n",
    "        rootURL = rootURL + \"A/\"\n",
    "        for z in range(26):\n",
    "            newURL = rootURL + azlist[z] + \"/\"\n",
    "            for y in range(26):\n",
    "                newerURL = newURL + azlist[y] \n",
    "                filenames.append(newerURL)\n",
    "                #print(newerURL)\n",
    "                \n",
    "    else:\n",
    "        rootURL = \"C:/Users/Danny/Documents/spring18/DataScience/FinalProject/millionsongsubset_full/MillionSongSubset/data/B/\"\n",
    "        for z2 in range(9):\n",
    "            newURL = rootURL + azlist[z2] + \"/\"\n",
    "            if (z2 < 8):\n",
    "                for y2 in range(26):\n",
    "                    newerURL = newURL + azlist[y2] \n",
    "                    #print(newerURL)\n",
    "                    filenames.append(newerURL)\n",
    "            else:\n",
    "                for y3 in range (10):\n",
    "                    newerURL = newURL + azlist[y3]\n",
    "                    #print(newerURL)\n",
    "                    filenames.append(newerURL)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullfilenames = []\n",
    "for i in range(len(filenames)):\n",
    "    onlyfiles = [f for f in listdir(filenames[i]) if isfile(join(filenames[i], f))]\n",
    "    for w in range(len(onlyfiles)):\n",
    "        fullfilenames.append(filenames[i]+\"/\"+ onlyfiles[w])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Danny/Documents/spring18/DataScience/FinalProject/millionsongsubset_full/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullfilenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import HDFStore, DataFrame\n",
    "import pandas as pd\n",
    "hdf =HDFStore(fullfilenames[0])\n",
    "df = hdf.select('analysis/songs') \n",
    "df2 = hdf.select('metadata/songs') \n",
    "df3 = hdf.select('musicbrainz/songs')\n",
    "hdf.close()\n",
    "df2cols = list(df2)\n",
    "df3cols = list(df3)\n",
    "for i in range(len(df2cols)):\n",
    "            df[df2cols[i]] = df2[df2cols[i]]\n",
    "for y in range(len(df3cols)):\n",
    "            df[df3cols[y]] = df3[df3cols[y]]\n",
    "df_final = df\n",
    "for f in range(1,len(fullfilenames)):\n",
    "    hdf =HDFStore(fullfilenames[f])\n",
    "    df = hdf.select('analysis/songs') \n",
    "    df2 = hdf.select('metadata/songs') \n",
    "    df3 = hdf.select('musicbrainz/songs')\n",
    "    hdf.close()\n",
    "    df2cols = list(df2)\n",
    "    df3cols = list(df3)\n",
    "    for i in range(len(df2cols)):\n",
    "               df[df2cols[i]] = df2[df2cols[i]]\n",
    "    for y in range(len(df3cols)):\n",
    "               df[df3cols[y]] = df3[df3cols[y]]\n",
    "    df_final = df_final.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.index = range(len(fullfilenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#to prove that energy values are zero regardless of using hdf5 getters class or HDFstore\n",
    "#import hdf5_getters\n",
    "#for f in range(100):# len(fullfilenames)):\n",
    "#    h5 = hdf5_getters.open_h5_file_read(fullfilenames[f])\n",
    "#    energy = hdf5_getters.get_energy(h5)\n",
    "#    h5.close()\n",
    "#    print(energy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"C:/Users/Danny/Documents/spring18/DataScience/FinalProject/convertedData.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
