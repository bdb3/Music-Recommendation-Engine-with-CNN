{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pandas import HDFStore, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootURL = \"C:/Users/Danny/Documents/spring18/DataScience/FinalProject/millionsongsubset_full/MillionSongSubset/data/\"\n",
    "import string\n",
    "s = string.ascii_uppercase[:27]\n",
    "azlist = []\n",
    "filenames = []\n",
    "for b in range(26):\n",
    "    azlist.append(s[b])\n",
    "for a in range(2):\n",
    "    if (a == 0):\n",
    "        rootURL = rootURL + \"A/\"\n",
    "        for z in range(26):\n",
    "            newURL = rootURL + azlist[z] + \"/\"\n",
    "            for y in range(26):\n",
    "                newerURL = newURL + azlist[y] \n",
    "                filenames.append(newerURL)\n",
    "                #print(newerURL)\n",
    "                \n",
    "    else:\n",
    "        rootURL = \"C:/Users/Danny/Documents/spring18/DataScience/FinalProject/millionsongsubset_full/MillionSongSubset/data/B/\"\n",
    "        for z2 in range(9):\n",
    "            newURL = rootURL + azlist[z2] + \"/\"\n",
    "            if (z2 < 8):\n",
    "                for y2 in range(26):\n",
    "                    newerURL = newURL + azlist[y2] \n",
    "                    #print(newerURL)\n",
    "                    filenames.append(newerURL)\n",
    "            else:\n",
    "                for y3 in range (10):\n",
    "                    newerURL = newURL + azlist[y3]\n",
    "                    #print(newerURL)\n",
    "                    filenames.append(newerURL)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullfilenames = []\n",
    "for i in range(len(filenames)):\n",
    "    onlyfiles = [f for f in listdir(filenames[i]) if isfile(join(filenames[i], f))]\n",
    "    for w in range(len(onlyfiles)):\n",
    "        fullfilenames.append(filenames[i]+\"/\"+ onlyfiles[w])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Danny/Documents/spring18/DataScience/FinalProject/millionsongsubset_full/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullfilenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import HDFStore, DataFrame\n",
    "import pandas as pd\n",
    "hdf =HDFStore(fullfilenames[0])\n",
    "df = hdf.select('analysis/songs') \n",
    "df2 = hdf.select('metadata/songs') \n",
    "df3 = hdf.select('musicbrainz/songs')\n",
    "df2cols = list(df2)\n",
    "df3cols = list(df3)\n",
    "for i in range(len(df2cols)):\n",
    "            df[df2cols[i]] = df2[df2cols[i]]\n",
    "for y in range(len(df3cols)):\n",
    "            df[df3cols[y]] = df3[df3cols[y]]\n",
    "df_final = df\n",
    "for f in range(1,len(fullfilenames)):\n",
    "    hdf =HDFStore(fullfilenames[f])\n",
    "    df = hdf.select('analysis/songs') \n",
    "    df2 = hdf.select('metadata/songs') \n",
    "    df3 = hdf.select('musicbrainz/songs')\n",
    "    hdf.close()\n",
    "    df2cols = list(df2)\n",
    "    df3cols = list(df3)\n",
    "    for i in range(len(df2cols)):\n",
    "               df[df2cols[i]] = df2[df2cols[i]]\n",
    "    for y in range(len(df3cols)):\n",
    "               df[df3cols[y]] = df3[df3cols[y]]\n",
    "    df_final = df_final.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.index = range(len(fullfilenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The file 'C:/Users/Danny/Documents/spring18/DataScience/FinalProject/millionsongsubset_full/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5' is already opened, but not in read-only mode (as requested).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-2cac4a9183f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#energy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mh5file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/Danny/Documents/spring18/DataScience/FinalProject/millionsongsubset_full/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"H5FD_CORE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Danny\\Anaconda3\\lib\\site-packages\\tables\\file.py\u001b[0m in \u001b[0;36mopen_file\u001b[1;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m                 raise ValueError(\n\u001b[0;32m    305\u001b[0m                     \u001b[1;34m\"The file '%s' is already opened, but \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m                     \"not in read-only mode (as requested).\" % filename)\n\u001b[0m\u001b[0;32m    307\u001b[0m             \u001b[1;31m# 'a' and 'r+' are compatible with everything except 'r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0momode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The file 'C:/Users/Danny/Documents/spring18/DataScience/FinalProject/millionsongsubset_full/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5' is already opened, but not in read-only mode (as requested)."
     ]
    }
   ],
   "source": [
    "import hdf5_getters\n",
    "#for f in range(len(fullfilenames)):\n",
    "#h5 = hdf5_getters.open_h5_file_read(\"C:/Users/Danny/Documents/spring18/DataScience/FinalProject/millionsongsubset_full/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5\")\n",
    "#energy = hdf5_getters.get_energy(h5)\n",
    "#h5.close()\n",
    "#energy\n",
    "import tables\n",
    "h5file = tables.open_file(\"C:/Users/Danny/Documents/spring18/DataScience/FinalProject/millionsongsubset_full/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5\", driver=\"H5FD_CORE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"C:/Users/Danny/Documents/spring18/DataScience/FinalProject/convertedData.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
